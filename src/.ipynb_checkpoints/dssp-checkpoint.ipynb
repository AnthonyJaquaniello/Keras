{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder #pour le one_hot_encoding.\n",
    "from keras.layers import Dense, Flatten, TimeDistributed #Flatten pour mettre à plat une matrice.\n",
    "from keras import Input, Model\n",
    "from keras.layers import add, Activation #add pour sommer les couches\n",
    "from keras.layers import Conv1D, AveragePooling1D #pour le pooling et la convolution.\n",
    "from keras.models import load_model\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction de structure secondaire par réseau de convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Processing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des seq\n",
    "x_train = []\n",
    "\n",
    "with open(\"../data/train.fasta\", \"r\") as file:\n",
    "    for line in file:\n",
    "        x_train.append(list(line[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion avec des \"0\" jusqu'a 759\n",
    "for seq in x_train:\n",
    "    seq.append(\"J\")\n",
    "    while len(seq) != 760:\n",
    "        seq.append(\"J\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "1348\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[1]))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des ddsp:\n",
    "y_train = []\n",
    "\n",
    "with open(\"../data/train.dssp\", 'r') as file:\n",
    "    for line in file:\n",
    "        y_train.append(list(line[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion jusqu'a 759:\n",
    "for d in y_train:\n",
    "    d.append(\"*\")\n",
    "    while len(d) != 760:\n",
    "        d.append(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "1348\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[1]))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 760, 21)\n"
     ]
    }
   ],
   "source": [
    "#traduction des X en one_hot_encoding:\n",
    "all_one_hot_x_train = []\n",
    "\n",
    "for i in range(0,len(x_train)):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(x_train[i])\n",
    "    one_hot_i = keras.utils.to_categorical(integer_encoded, num_classes= 21)  \n",
    "    all_one_hot_x_train.append(one_hot_i)\n",
    "all_one_hot_x_train = np.array(all_one_hot_x_train)\n",
    "print(all_one_hot_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 760, 4)\n"
     ]
    }
   ],
   "source": [
    "#traduction des Y en one_hot_encoding:\n",
    "all_one_hot_y_train = []\n",
    "\n",
    "for j in range(0,len(y_train)):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(y_train[j])\n",
    "    one_hot_j = keras.utils.to_categorical(integer_encoded, num_classes= 4)\n",
    "    all_one_hot_y_train.append(one_hot_j)\n",
    "all_one_hot_y_train = np.array(all_one_hot_y_train)\n",
    "print(all_one_hot_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#façon de tester\n",
    "all_one_hot_y_train.shape\n",
    "np.unique(all_one_hot_y_train[:,758,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des seq\n",
    "x_test = []\n",
    "\n",
    "with open(\"../data/blind.fasta\", \"r\") as file:\n",
    "    for line in file:\n",
    "        x_test.append(list(line[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion avec des \"0\" jusqu'a 759\n",
    "for seq in x_test:\n",
    "    seq.append(\"J\")\n",
    "    while len(seq) != 760:\n",
    "        seq.append(\"J\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "\n",
    "with open(\"../data/blind.dssp\", 'r') as file:\n",
    "    for line in file:\n",
    "        y_test.append(list(line[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion jusqu'a 759:\n",
    "for d in y_test:\n",
    "    d.append(\"*\")\n",
    "    while len(d) != 760:\n",
    "        d.append(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 760, 21)\n"
     ]
    }
   ],
   "source": [
    "#traduction des X en one_hot_encoding:\n",
    "all_one_hot_x_test = []\n",
    "\n",
    "for i in range(0,len(x_test)):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(x_test[i])\n",
    "    one_hot_i = keras.utils.to_categorical(integer_encoded, num_classes = 21)  \n",
    "    all_one_hot_x_test.append(one_hot_i)\n",
    "all_one_hot_x_test = np.array(all_one_hot_x_test)\n",
    "print(all_one_hot_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 760, 4)\n"
     ]
    }
   ],
   "source": [
    "#traduction des Y en one_hot_encoding:\n",
    "all_one_hot_y_test = []\n",
    "\n",
    "for j in range(0,len(y_test)):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(y_test[j])\n",
    "    one_hot_j = keras.utils.to_categorical(integer_encoded, num_classes = 4)  \n",
    "    all_one_hot_y_test.append(one_hot_j)\n",
    "all_one_hot_y_test = np.array(all_one_hot_y_test)\n",
    "print(all_one_hot_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Construction du réseau CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=21, kernel_size=3, strides=1, padding= \"same\", activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Conv1D(filters=21, kernel_size=3, strides=1, padding= \"same\", activation = \"linear\", kernel_initializer=\"he_normal\"))\n",
    "model.add(TimeDistributed(Dense(4,activation = \"softmax\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 68 samples\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 4s 3ms/step - loss: 0.2062 - accuracy: 0.9010 - val_loss: 0.2580 - val_accuracy: 0.8771\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2062 - accuracy: 0.9010 - val_loss: 0.2537 - val_accuracy: 0.8801\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2060 - accuracy: 0.9013 - val_loss: 0.2571 - val_accuracy: 0.8783\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.2562 - val_accuracy: 0.8787\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2060 - accuracy: 0.9013 - val_loss: 0.2540 - val_accuracy: 0.8802\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2063 - accuracy: 0.9010 - val_loss: 0.2554 - val_accuracy: 0.8791\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2056 - accuracy: 0.9014 - val_loss: 0.2538 - val_accuracy: 0.8803\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2055 - accuracy: 0.9015 - val_loss: 0.2592 - val_accuracy: 0.8757\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2050 - accuracy: 0.9020 - val_loss: 0.2532 - val_accuracy: 0.8803\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2051 - accuracy: 0.9019 - val_loss: 0.2548 - val_accuracy: 0.8795\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2052 - accuracy: 0.9018 - val_loss: 0.2581 - val_accuracy: 0.8765\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2049 - accuracy: 0.9020 - val_loss: 0.2546 - val_accuracy: 0.8798\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.2047 - accuracy: 0.9020 - val_loss: 0.2527 - val_accuracy: 0.8809\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2045 - accuracy: 0.9022 - val_loss: 0.2532 - val_accuracy: 0.8806\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2047 - accuracy: 0.9022 - val_loss: 0.2535 - val_accuracy: 0.8809\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2044 - accuracy: 0.9025 - val_loss: 0.2539 - val_accuracy: 0.8804\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2046 - accuracy: 0.9022 - val_loss: 0.2536 - val_accuracy: 0.8802\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2046 - accuracy: 0.9022 - val_loss: 0.2546 - val_accuracy: 0.8795\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2044 - accuracy: 0.9023 - val_loss: 0.2545 - val_accuracy: 0.8796\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2046 - accuracy: 0.9022 - val_loss: 0.2551 - val_accuracy: 0.8795\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2043 - accuracy: 0.9023 - val_loss: 0.2568 - val_accuracy: 0.8779\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.2549 - val_accuracy: 0.8799\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2040 - accuracy: 0.9025 - val_loss: 0.2528 - val_accuracy: 0.8812\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff2a74c6710>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "stop_criteria =  EarlyStopping(monitor=\"val_loss\", mode = \"min\",verbose = 1, patience = 10)\n",
    "best_model_path = \"../results/my_model\"+\".h5\"\n",
    "best_model = ModelCheckpoint(best_model_path, monitor = \"val_loss\", verbose = 2, save_best_only = True)\n",
    "my_model = load_model(\"../results/my_model.h5\")\n",
    "my_model.fit(all_one_hot_x_train,all_one_hot_y_train,epochs=50, batch_size = 20,\n",
    "          validation_split = 0.05, callbacks = [stop_criteria])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348/1348 [==============================] - 1s 607us/step\n",
      "[0.20970194514851895, 0.8992933034896851]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(all_one_hot_x_train, all_one_hot_y_train)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention cependant, ces performances sont trop élevées, cela doit venir des 0 et des '*' que l'on a ajouté pour compléter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp = 2386\n",
      "tot = 5257\n",
      "ACC:45.387\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(all_one_hot_x_test)\n",
    "predictions = my_model.predict(all_one_hot_x_test)\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "tot = 0\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        if all_one_hot_y_test[i,j,3] != 0:\n",
    "            predmax = -1\n",
    "            predict_class = -1\n",
    "            true_class = -1\n",
    "            for k in range(len(predictions[i,j])):\n",
    "                if predmax < predictions[i,j,k]:\n",
    "                    predmax = predictions[i,j,k]\n",
    "                    predict_class=k\n",
    "                if all_one_hot_y_test[i,j,k] == 1.:\n",
    "                    true_class = k\n",
    "            if predict_class == true_class:\n",
    "                tp = tp+1\n",
    "            tot=tot+1\n",
    "print(\"tp =\", tp)\n",
    "print(\"tot =\", tot)\n",
    "print(\"ACC:%5.3f\"%(tp/tot*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Réseau Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_module(lay_i, n_filters):\n",
    "    if lay_i.shape[-1] != n_filters:\n",
    "        lay_i = Conv1D(n_filters, (1), padding=\"same\", activation=\"relu\",kernel_initializer=\"he_normal\")(lay_i)\n",
    "    save = lay_i\n",
    "    conv_1 = Conv1D(n_filters, (3), padding=\"same\", activation=\"relu\",kernel_initializer=\"he_normal\")(lay_i)\n",
    "    conv_2 = Conv1D(n_filters, (3), padding=\"same\", activation=\"linear\",kernel_initializer=\"he_normal\")(conv_1)\n",
    "    conc_1 = add([conv_2, save])\n",
    "    output = Activation(\"relu\")(conc_1)\n",
    "\n",
    "    return output\n",
    "\n",
    "def my_model():\n",
    "    n_residual = 5\n",
    "    print(\"Simple residual network with {} modules\".format(n_residual))\n",
    "    inputs = Input(shape=(760, 21))\n",
    "    residual_i = inputs\n",
    "    for _ in range(n_residual):\n",
    "        residual_i = residual_module(residual_i, 24)\n",
    "\n",
    "    output = TimeDistributed(Dense(4, activation=\"softmax\"))(residual_i)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple residual network with 5 modules\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 760, 21)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 760, 24)      528         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 760, 24)      1752        conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 760, 24)      1752        conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 760, 24)      0           conv1d_48[0][0]                  \n",
      "                                                                 conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 760, 24)      0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 760, 24)      1752        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 760, 24)      1752        conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 760, 24)      0           conv1d_50[0][0]                  \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 760, 24)      0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 760, 24)      1752        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 760, 24)      1752        conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 760, 24)      0           conv1d_52[0][0]                  \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 760, 24)      0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 760, 24)      1752        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 760, 24)      1752        conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 760, 24)      0           conv1d_54[0][0]                  \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 760, 24)      0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 760, 24)      1752        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 760, 24)      1752        conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 760, 24)      0           conv1d_56[0][0]                  \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 760, 24)      0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 760, 4)       100         activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 18,148\n",
      "Trainable params: 18,148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1348/1348 [==============================] - 7s 5ms/step - loss: 0.3726 - accuracy: 0.8378\n",
      "Epoch 2/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.8744\n",
      "Epoch 3/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2238 - accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "1348/1348 [==============================] - 6s 4ms/step - loss: 0.2181 - accuracy: 0.8912\n",
      "Epoch 5/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2132 - accuracy: 0.8951\n",
      "Epoch 6/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2115 - accuracy: 0.8967\n",
      "Epoch 7/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2093 - accuracy: 0.8985\n",
      "Epoch 8/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2077 - accuracy: 0.8996\n",
      "Epoch 9/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2061 - accuracy: 0.9008\n",
      "Epoch 10/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.2049 - accuracy: 0.9016\n",
      "Epoch 11/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2070 - accuracy: 0.9002\n",
      "Epoch 12/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2029 - accuracy: 0.9034\n",
      "Epoch 13/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.2029 - accuracy: 0.9032\n",
      "Epoch 14/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.2020 - accuracy: 0.9037\n",
      "Epoch 15/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2015 - accuracy: 0.9043\n",
      "Epoch 16/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2015 - accuracy: 0.9041\n",
      "Epoch 17/20\n",
      "1348/1348 [==============================] - 5s 4ms/step - loss: 0.2000 - accuracy: 0.9052\n",
      "Epoch 18/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.1994 - accuracy: 0.9053\n",
      "Epoch 19/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.1993 - accuracy: 0.9057\n",
      "Epoch 20/20\n",
      "1348/1348 [==============================] - 5s 3ms/step - loss: 0.1977 - accuracy: 0.9068\n",
      "149/149 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19356051147384132, 0.9059078097343445]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = my_model()\n",
    "resnet.fit(all_one_hot_x_train, all_one_hot_y_train, batch_size=20, epochs=20)\n",
    "resnet.evaluate(all_one_hot_x_test, all_one_hot_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp = 2605\n",
      "tot = 5257\n",
      "ACC:49.553\n"
     ]
    }
   ],
   "source": [
    "predictions = resnet.predict(all_one_hot_x_test)\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "tot = 0\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        if all_one_hot_y_test[i,j,3] != 0:\n",
    "            predmax = -1\n",
    "            predict_class = -1\n",
    "            true_class = -1\n",
    "            for k in range(len(predictions[i,j])):\n",
    "                if predmax < predictions[i,j,k]:\n",
    "                    predmax = predictions[i,j,k]\n",
    "                    predict_class=k\n",
    "                if all_one_hot_y_test[i,j,k] == 1.:\n",
    "                    true_class = k\n",
    "            if predict_class == true_class:\n",
    "                tp = tp+1\n",
    "            tot=tot+1\n",
    "print(\"tp =\", tp)\n",
    "print(\"tot =\", tot)\n",
    "print(\"ACC:%5.3f\"%(tp/tot*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
